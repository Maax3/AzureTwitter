{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e86afbae-e41e-4cce-adbb-1d99cf1831bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Configuración de token SAS para la conexión con Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5db91f6c-b00e-4cda-a38c-458fed4f08a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.auth.type.tweetsfiles.dfs.core.windows.net\", \"SAS\")\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.tweetsfiles.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.tweetsfiles.dfs.core.windows.net\", \"sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2024-07-07T22:27:21Z&st=2024-05-04T14:27:21Z&spr=https&sig=hNwdq5gK3xFj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75377729-fbc3-4142-b8a0-4a32996495c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Instalación de dependencias necesarias\n",
    "* Librería de sentimiento utilizada: https://github.com/sentiment-analysis-spanish/sentiment-spanish/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c354cf6-2a84-4afa-8487-17e9218f10f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn) (1.9.1)\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /databricks/python3/lib/python3.10/site-packages (from scipy) (1.21.5)\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting sentiment-analysis-spanish\n",
      "  Using cached sentiment_analysis_spanish-0.0.25-py3-none-any.whl (30.0 MB)\n",
      "Installing collected packages: sentiment-analysis-spanish\n",
      "Successfully installed sentiment-analysis-spanish-0.0.25\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#%pip install transformers\n",
    "#%pip install torch\n",
    "#dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab8fcd38-25e8-4fa4-bbfc-7165a9336b9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35a566ee-de1b-4071-8da7-4a32bc13828d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-2542129566031017>, line 7\u001b[0m\n",
       "\u001b[1;32m      5\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
       "\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#variables con los valores de Azure\u001b[39;00m\n",
       "\u001b[0;32m----> 7\u001b[0m filename \u001b[38;5;241m=\u001b[39m dbutils\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name_origin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[1;32m      8\u001b[0m routename \u001b[38;5;241m=\u001b[39m dbutils\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_route_databricks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[1;32m      9\u001b[0m destination \u001b[38;5;241m=\u001b[39m dbutils\u001b[38;5;241m.\u001b[39mwidgets\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination_file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
       "\u001b[0;31mNameError\u001b[0m: name 'dbutils' is not defined\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "#variables con los valores de Azure\n",
    "filename = dbutils.widgets.get('file_name_origin')\n",
    "routename = dbutils.widgets.get('save_route_databricks')\n",
    "destination = dbutils.widgets.get('destination_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d3b26c7-8f18-4a94-8664-776cf2c64a56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('timestamp', StringType(), True),\n",
    "    StructField('tweet_id', StringType(), True),\n",
    "    StructField('content', StringType(), True),\n",
    "    StructField('username', StringType(), True),\n",
    "    StructField('followers_count', StringType(), True),\n",
    "    StructField('location', StringType(), True),\n",
    "    StructField('language', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d670843-090b-4d79-8423-7cfc32de1fa4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Crear un dataframe de spark y pandas a partir del archivo de origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f7c4e5f-ecb1-48eb-890a-16c520b18313",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tweets_df = spark.read.format('csv').options(header='true', delimiter=',').schema(schema).load(filename)\n",
    "tweets_pd = tweets_df.toPandas()\n",
    "tweets_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d25e7c5b-253f-4c13-8c24-0879243c29fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Proceso de limpieza del dataframe (dataframe de pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41b67f6-24f6-4a65-b6c6-119fd419fa89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convertir timestamp a datetime y eliminar duplicados y nulos\n",
    "tweets_pd['timestamp'] = pd.to_datetime(tweets_pd['timestamp'], errors='coerce')\n",
    "tweets_pd.dropna(subset=['timestamp', 'tweet_id', 'content', 'username', 'language'], inplace=True)\n",
    "tweets_pd.drop_duplicates(subset=['tweet_id'], inplace=True)\n",
    "tweets_pd = tweets_pd[tweets_pd['language'] == 'es']\n",
    "tweets_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86f53943-f5f7-497d-afe1-99143d51b136",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00d92ff2-ef45-46b0-a02a-fd25b9a02880",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sentiment_analysis_spanish import sentiment_analysis\n",
    "sentiment = sentiment_analysis.SentimentAnalysisSpanish()\n",
    "tweets_pd['sentimiento'] = tweets_pd['content'].apply(sentiment.sentiment)\n",
    "tweets_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26e31549-f683-4d5b-91ff-0e39b95bc2be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Convertir el dataframe a un dataframe de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c920292-d2a0-49cc-bd57-7f9b0de3dfe6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tweets_df_limpio = spark.createDataFrame(tweets_pd)\n",
    "tweets_df_limpio.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0d3b98b-89ad-4623-bbdd-8269db7d389b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Guardar el resultado en el destino de Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a284d29b-cb1e-463f-9113-b223485e0f3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tweets_df_limpio.write.format('csv').option('header', 'true').save(destination)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "author": "Brian Durán",
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "allowScalar": false
   },
   "rootExistingClusterId": "0525-230257-xdf7d98p",
   "rootTarget": "",
   "untrustedLibraries": []
  },
  "application/vnd.databricks.v1+notebook-namespace": "brianduran",
  "application/vnd.databricks.v1+notebook-options": {
   "byteLimit": 2048000,
   "rowLimit": 10000
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
